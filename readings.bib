@article{Anderson1991,
abstract = {Abstract: Can the output of human cognition be predicted from the assumption that it is an optimal response to the informationprocessing demands of the environment? Amethodology called rational analysis is described for deriving predictions about cognitive phenomena using optimization assumptions The predictions flow from the statistical structure of the environment and not the assumed structure of the mind Bayesian inference is used, assuming that people shut with a weak prior model or the world which they integrate with experience to develop stronger models of specific aspects of the world Cognitive performance maximizes the difference between the expected gain and cost of mental effort (1) Memory performance can be predicted on the assumption that retrieval seeks a maximal trade-off between the probability of finding the relevant memories and the effort required to do so; in (2) categorization performance there is a similar trade-off between accuracy in predicting object features and the cost of hypothesis formation; in (3) casual inference the trode-off is between accuracy in predicting future events and the cost of hypothesis formation; and in (4) problem solving it is between the probability of achieving goals and the cost of both external and mental problem-solving search The implcmention of these rational prescriptions in neurally plausible architecture is also discussed},
author = {Anderson, John R},
doi = {10.1017/S0140525X00070801},
file = {:Users/jhamrick/Dropbox/Papers/1991/Anderson - Is human cognition adaptive.pdf:pdf},
isbn = {1469-1825 (Electronic); 0140-525X (Print)},
issn = {0140-525X},
journal = {The Behavioral and Brain Sciences},
keywords = {1,111en1ory,a rational theory of,adaptation to its environ111ent,bayes,categorization,causal infe1ence,cognition,eo1nputation,hu111an cognition as an,long hadition of trying,optitnality,problcn1 solving,rationality,the,there has been a,to understand},
number = {3},
pages = {471--485},
title = {Is human cognition adaptive?},
volume = {14},
year = {1991}
}
@article{Aoude2013,
author = {Aoude, Georges S. and Luders, Brandon D. and Joseph, Joshua M. and Roy, Nicholas and How, Jonathan P},
doi = {10.1007/s10514-013-9334-3},
file = {:Users/jhamrick/Dropbox/Papers/2013/Aoude et al. - Probabilistically safe motion planning to avoid dynamic obstacles with uncertain motion patterns.pdf:pdf},
issn = {09295593},
journal = {Autonomous Robots},
keywords = {Gaussian processes,Planning under uncertainty,Trajectory prediction},
number = {1},
pages = {51--76},
title = {Probabilistically safe motion planning to avoid dynamic obstacles with uncertain motion patterns},
volume = {35},
year = {2013}
}
@article{Baraff1997,
abstract = {This portion of the course notes deals with the problem of rigid body dynamics. To help get you started simulating rigid body motion, we’ve provided code fragments that implement most of the concepts discussed in these notes. This segment of the course notes is divided into two parts. The first part covers the motion of rigid bodies that are completely unconstrained in their allowable motion; that is, simulations that aren’t concerned about collisions between rigid bodies. Given any external forces acting on a rigid body, we’ll show how to simulate the motion of the body in response to these forces. The mathematical derivations in these notes are meant to be fairly informal and intuitive. The second part of the notes tackles the problem of constrained motion that arises when we regard bodies as solid, and need to disallow inter-penetration. We enforce these non-penetration constraints by computing appropriate contact forces between contacting bodies. Given values for these contact forces, simulation proceeds exactly as in the unconstrained case: we simply apply all the forces to the bodies and let the simulation unfold as though the motions of bodies are completely unconstrained. If we have computed the contact forces correctly, the resulting motion of the bodies will be free from inter-penetration. The computation of these contact forces is the most demanding component of the entire simulation process.},
author = {Baraff, David},
file = {:Users/jhamrick/Dropbox/Papers/1997/Baraff - Rigid body simulation unconstrained rigid body dynamics.pdf:pdf},
journal = {ACM SIGGRAPH 1997 Course Notes for ``An Introduction to Physically Based Modeling''},
title = {Rigid body simulation: unconstrained rigid body dynamics},
url = {http://www.cs.cmu.edu/~baraff/pbm/rigid1.pdf},
year = {1997}
}
@incollection{Battaglia2012,
author = {Battaglia, Peter W and Kersten, Daniel and Schrater, Paul R},
booktitle = {Sensory Cue Integration},
editor = {Trommershauser, Julia and K{\"{o}}rding, Konrad P and Landy, Michael S},
file = {:Users/jhamrick/Dropbox/Papers/2012/Battaglia, Kersten, Schrater - The Role of Generative Knowledge in Object Perception.pdf:pdf},
keywords = {generative knowledge,perception,perceptual judgments,sensory cues},
publisher = {Oxford University Press},
title = {The Role of Generative Knowledge in Object Perception},
year = {2012}
}
@article{Bergen2007,
abstract = {There is mounting evidence that language comprehension involves the activation of mental imagery of the content of utterances (Barsalou, 1999; Bergen, Chang, \& Narayan, 2004; Bergen, Narayan, \& Feldman, 2003; Narayan, Bergen, \& Weinberg, 2004; Richardson, Spivey, McRae, \& Barsalou, 2003; Stanfield \& Zwaan, 2001; Zwaan, Stanfield, \& Yaxley, 2002). This imagery can have motor or perceptual content. Three main questions about the process remain under-explored, however. First, are lexical associations with perception or motion sufficient to yield mental simulation, or is the integration of lexical semantics into larger structures, like sentences, necessary? Second, what linguistic elements (e.g., verbs, nouns, etc.) trigger mental simulations? Third, how detailed are the visual simulations that are performed? A series of behavioral experiments address these questions, using a visual object categorization task to investigate whether up- or down-related language selectively interferes with visual processing in the same part of the visual field (following Richardson et al., 2003). The results demonstrate that either subject nouns or main verbs can trigger visual imagery, but only when used in literal sentences about real space-metaphorical language does not yield significant effects-which implies that it is the comprehension of the sentence as a whole and not simply lexical associations that yields imagery effects. These studies also show that the evoked imagery contains detail as to the part of the visual field where the described scene would take place.},
author = {Bergen, Benjamin K and Lindsay, Shane and Matlock, Teenie and Narayanan, Srini},
doi = {10.1080/03640210701530748},
file = {:Users/jhamrick/Dropbox/Papers/2007/Bergen et al. - Spatial and linguistic aspects of visual imagery in sentence comprehension.pdf:pdf},
issn = {0364-0213},
journal = {Cognitive Science},
keywords = {abstract concepts,communication,human experimentation,language understanding,linguistics,mental simulation,perception,psychology,semantics,spatial cognition},
month = {sep},
number = {5},
pages = {733--64},
pmid = {21635316},
title = {Spatial and linguistic aspects of visual imagery in sentence comprehension},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21635316},
volume = {31},
year = {2007}
}
@article{Bertuccelli2012,
author = {Bertuccelli, Luca F and Bethke, Brett and How, Jonathan P},
doi = {10.1109/MCS.2012.2205478},
file = {:Users/jhamrick/Dropbox/Papers/2012/Bertuccelli, Bethke, How - Robust adaptive Markov decision processes Planning with model uncertainty.pdf:pdf},
journal = {IEEE Control Systems Magazine},
title = {Robust adaptive {Markov} decision processes: Planning with model uncertainty},
year = {2012}
}
@article{Bever2010,
abstract = {This contribution reviews (some of) the history of analysis by synthesis, an approach to perception and comprehension articulated in the 1950s. Whereas much research has focused on bottom-up, feed-forward, inductive mechanisms, analysis by synthesis as a heuristic model emphasizes a balance of bottom-up and knowledge-driven, top-down, predictive steps in speech perception and language comprehension. This idea aligns well with contemporary Bayesian approaches to perception (in language and other domains), which are illustrated with examples from different aspects of per-ception and comprehension. Results from psycholinguistics, the cognitive neuroscience of language, and visual object recognition suggest that analysis by synthesis can provide a productive way of structuring biolinguistic re-search. Current evidence suggests that such a model is theoretically well motivated, biologically sensible, and becomes computationally tractable bor-rowing from Bayesian formalizations. 1. The Problem It is a commonplace that perception is in part constructive (e.g., James 1890). The computational mind takes imperfect, blurred, and continuously varying input and reports out discrete representations. The corresponding empirical problem for language exists in several dimensions — phonetic, lexical, phrasal, proposi-tional, and semantic. In each case, the surface input data are insufficient to account for all of what is perceived and used as discrete categories. A large part of the problem derives from the fact that each language is different in its details and there is no computationally tractable upper bound on the number of possible utterances to be perceived. Thus, each level of the perceptual process must involve a creative component, tuned to each input utterance. We review an old solution to this problem, which is gaining new currency because of advances in behavioral, computational and neurobiological research. This solution, 'analysis by synthesis' (AxS), combines hypotheses about the input with the computational re-creation of the input, as a way to combine the contributions of perception and computational reconstruction. We sketch some of the old and new evidence that},
author = {Bever, Thomas G and Poeppel, David},
file = {:Users/jhamrick/Dropbox/Papers/2010/Bever, Poeppel - Analysis by Synthesis A (Re-)Emerging Program of Research for Language and Vision.pdf:pdf},
journal = {Biolinguistics},
keywords = {language comprehension,neurolinguistics,predictive coding,sentence processing,speech perception},
number = {2},
pages = {174--200},
title = {Analysis by Synthesis: A (Re-)Emerging Program of Research for Language and Vision},
url = {http://www.psych.nyu.edu/clash/dp_papers/bever.poeppel.pdf},
volume = {43},
year = {2010}
}
@article{Bocsi2011,
abstract = {Learning inverse kinematics of robots with redundant degrees of freedom (DoF) is a difficult problem in robot learning. The difficulty lies in the non-uniqueness of the inverse kinematics function. Existing methods tackle non-uniqueness by segmenting the configuration space and building a global solution from local experts. The usage of local experts implies the definition of an oracle, which governs the global consistency of the local models; the definition of this oracle is difficult. We propose an algorithm suitable to learn the inverse kinematics function in a single global model despite its multivalued nature. Inverse kinematics is approximated from examples using structured output learning methods. Unlike most of the existing methods, which estimate inverse kinematics on velocity level, we address the learning of the direct function on position level. This problem is a significantly harder. To support the proposed method, we conducted real world experiments on a tracking control task and tested our algorithms on these models.},
author = {B{\'{o}}csi, Botond and Nguyen-Tuong, Duy and Csat{\'{o}}, Lehel and Sch{\"{o}}lkopf, Bernhard and Peters, Jan},
doi = {10.1109/IROS.2011.6094666},
file = {:Users/jhamrick/Dropbox/Papers/2011/B{\'{o}}csi et al. - Learning inverse kinematics with structured prediction.pdf:pdf},
journal = {Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems},
title = {Learning inverse kinematics with structured prediction},
year = {2011}
}
@article{Boeing2007,
abstract = {We present a qualitative evaluation of a number of free publicly available physics engines for simulation systems and game development. A brief overview of the aspects of a physics engine is presented accompanied by a comparison of the capabilities of each physics engine. Aspects that are investigated the accuracy and computational efficiency of the integrator properties, material properties, stacks, links, and collision detection system.},
author = {Boeing, Adrian and Br{\"{a}}unl, Thomas},
doi = {10.1145/1321261.1321312},
file = {:Users/jhamrick/Dropbox/Papers/2007/Boeing, Br{\"{a}}unl - Evaluation of real-time physics simulation systems.pdf:pdf},
isbn = {9781595939128},
issn = {1595939121},
journal = {Proceedings of the 5th International Conference on Computer Graphics and Interactive Techniques in Australia and Southeast Asia},
keywords = {categories,computational,computer graphics,d,dynamic simulation,evaluation,geometry and object modeling,i,physically based modeling,physics engine,software architectures - data,software engineering},
number = {212},
title = {Evaluation of real-time physics simulation systems},
volume = {1},
year = {2007}
}
@article{Brand1995,
author = {Brand, Matthew and Cooper, Paul and Birnbaum, Lawrence},
doi = {10.1109/PBMCV.1995.514679},
file = {:Users/jhamrick/Dropbox/Papers/1995/Brand, Cooper, Birnbaum - Seeing Physics, or Physics is for Prediction.pdf:pdf},
journal = {Proceedings of the Workshop on Physics Based Modelling in Computer Vision},
title = {Seeing Physics, or: Physics is for Prediction},
year = {1995}
}
@article{Bridson2003,
abstract = {Clothing is a fundamental part of a character's persona, a key storytelling tool used to convey an intended impression to the audience. Draping, folding, wrinkling, stretching, etc. all convey meaning, and thus each is carefully controlled when filming live actors. When making films with computer simulated cloth, these subtle but important elements must be captured. In this paper we present several methods essential to matching the behavior and look of clothing worn by digital stand-ins to their real world counterparts. Novel contributions include a mixed explicit/implicit time integration scheme, a physically correct bending model with (potentially) nonzero rest angles for pre-shaping wrinkles, an interface forecasting technique that promotes the development of detail in contact regions, a post-processing method for treating cloth-character collisions that preserves folds and wrinkles, and a dynamic constraint mechanism that helps to control large scale folding. The common goal of all these techniques is to produce a cloth simulation with many folds and wrinkles improving the realism.},
author = {Bridson, R and Marino, S and Fedkiw, R},
doi = {10.1145/1198555.1198573},
file = {:Users/jhamrick/Dropbox/Papers/2003/Bridson, Marino, Fedkiw - Simulation of clothing with folds and wrinkles.pdf:pdf},
isbn = {1581136595},
journal = {ACM SIGGRAPH 2005 Courses},
pages = {28--36},
title = {Simulation of clothing with folds and wrinkles},
url = {http://portal.acm.org/citation.cfm?doid=1198555.1198573},
volume = {21},
year = {2003}
}
@article{Chater1999,
abstract = {Rational analysis is an empirical program that attempts to explain the function and purpose of cognitive processes. This article looks back on a decade of research outlining the rational analysis methodology and how the approach relates to other work in cognitive science. We illustrate rational analysis by considering how it has been applied to memory and reasoning. From the perspective of traditional cognitive science, the cognitive system can appear to be a rather arbitrary assortment of mechanisms with equally arbitrary limitations. In contrast, rational analysis views cognition as intricately adapted to its environment and to the problems it faces.},
author = {Chater, N and Oaksford, Mike},
doi = {10.1016/S1364-6613(98)01273-X},
file = {:Users/jhamrick/Dropbox/Papers/1999/Chater, Oaksford - Ten years of the rational analysis of cognition.pdf:pdf},
isbn = {1879-307X (Electronic)\r1364-6613 (Linking)},
issn = {1364-6613},
journal = {Trends in Cognitive Science},
number = {2},
pages = {57--65},
pmid = {10234228},
title = {Ten years of the rational analysis of cognition},
volume = {3},
year = {1999}
}
@article{Chib1995,
abstract = {Chib, S.},
author = {Chib, S and Greenberg, E},
doi = {10.1080/00031305.1995.10476177},
file = {:Users/jhamrick/Dropbox/Papers/1995/Chib, Greenberg - Understanding the Metropolis-Hastings algorithm.pdf:pdf},
journal = {The American Statistician},
pages = {327--335},
title = {Understanding the {Metropolis-Hastings} algorithm.},
volume = {49},
year = {1995}
}
@article{Clark2013,
abstract = {Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this "hierarchical prediction machine" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.},
author = {Clark, Andy},
doi = {10.1017/S0140525X12000477},
file = {:Users/jhamrick/Dropbox/Papers/2013/Clark - Whatever next Predictive brains, situated agents, and the future of cognitive science.pdf:pdf},
isbn = {1469-1825 (Electronic)\r0140-525X (Linking)},
issn = {1469-1825},
journal = {The Behavioral and Brain Sciences},
keywords = {Attention,Attention: physiology,Brain,Brain: physiology,Cognition,Cognition: physiology,Cognitive Science,Cognitive Science: trends,Humans,Learning,Learning: physiology,Models, Neurological,Perception,Perception: physiology},
number = {3},
pages = {181--204},
pmid = {23663408},
title = {Whatever next? Predictive brains, situated agents, and the future of cognitive science.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23663408},
volume = {36},
year = {2013}
}
@article{Clement2009,
author = {Clement, John J.},
doi = {10.1111/j.1756-8765.2009.01031.x},
file = {:Users/jhamrick/Dropbox/Papers/2009/Clement - The Role of Imagistic Simulation in Scientific Thought Experiments.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {embodied cognition,imagery,mental simulation,reasoning,scientific thinking},
month = {oct},
number = {4},
pages = {686--710},
title = {The Role of Imagistic Simulation in Scientific Thought Experiments},
url = {http://doi.wiley.com/10.1111/j.1756-8765.2009.01031.x},
volume = {1},
year = {2009}
}
@article{Courty2008,
author = {Courty, Nicolas and Arnaud, Elise},
doi = {10.1007/978-3-540-70517-8_1},
file = {:Users/jhamrick/Dropbox/Papers/2008/Courty, Arnaud - Inverse Kinematics Using Sequential Monte Carlo Methods.pdf:pdf},
journal = {Proceedings of the 5th Conference on Articulated Motion and Deformable Objects},
title = {Inverse Kinematics Using Sequential {Monte Carlo} Methods},
year = {2008}
}
@article{Davis,
author = {Davis, Ernest and Marcus, Gary F},
file = {:Users/jhamrick/Dropbox/Papers/Unknown/Davis, Marcus - The Scope and Limits of Simulation in Automated Reasoning.pdf:pdf},
journal = {Artificial Intelligence},
year = {to appear},
title = {The Scope and Limits of Simulation in Automated Reasoning},
url = {http://www.cs.nyu.edu/faculty/davise/papers/SimulationSubmitAIJ.pdf}
}
@article{Davis2014,
archivePrefix = {arXiv},
arxivId = {1506.04956},
author = {Davis, Ernest and Marcus, Gary F},
eprint = {1506.04956},
file = {:Users/jhamrick/Dropbox/Papers/2014/Davis, Marcus - The Scope and Limits of Simulation in Cognitive Models.pdf:pdf},
journal = {arXiv:1506.04956 [cs.AI]},
keywords = {physical reasoning,physics engine,simulation},
title = {The Scope and Limits of Simulation in Cognitive Models},
url = {http://arxiv.org/abs/1506.04956},
year = {2014}
}
@article{Ernst2002,
abstract = {When a person looks at an object while exploring it with their hand, vision and touch both provide information for estimating the properties of the object. Vision frequently dominates the integrated visual-haptic percept, for example when judging size, shape or position, but in some circumstances the percept is clearly affected by haptics. Here we propose that a general principle, which minimizes variance in the final estimate, determines the degree to which vision or haptics dominates. This principle is realized by using maximum-likelihood estimation to combine the inputs. To investigate cue combination quantitatively, we first measured the variances associated with visual and haptic estimation of height. We then used these measurements to construct a maximum-likelihood integrator. This model behaved very similarly to humans in a visual-haptic task. Thus, the nervous system seems to combine visual and haptic information in a fashion that is similar to a maximum-likelihood integrator. Visual dominance occurs when the variance associated with visual estimation is lower than that associated with haptic estimation.},
author = {Ernst, Marc O and Banks, Martin S},
doi = {10.1038/415429a},
file = {:Users/jhamrick/Dropbox/Papers/2002/Ernst, Banks - Humans integrate visual and haptic information in a statistically optimal fashion.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {6870},
pages = {429--433},
pmid = {11807554},
title = {Humans integrate visual and haptic information in a statistically optimal fashion},
volume = {415},
year = {2002}
}
@article{Finke1988,
author = {Finke, Ronald A and Slayton, Karen},
doi = {10.3758/BF03197758},
file = {:Users/jhamrick/Dropbox/Papers/1988/Finke, Slayton - Explorations of creative visual synthesis in mental imagery.pdf:pdf},
journal = {Memory \& Cognition},
number = {3},
pages = {252--257},
title = {Explorations of creative visual synthesis in mental imagery},
volume = {16},
year = {1988}
}
@article{Fischer2008,
abstract = {A growing body of research suggests that comprehending verbal descriptions of actions relies on an internal simulation of the described action. To assess this motor resonance account of language comprehension, we first review recent developments in the literature on perception and action, with a view towards language processing. We then examine studies of language processing from an action simulation perspective. We conclude by discussing several criteria that might be helpful with regard to assessing the role of motor resonance during language comprehension.},
author = {Fischer, Martin H and Zwaan, Rolf A},
doi = {10.1080/17470210701623605},
file = {:Users/jhamrick/Dropbox/Papers/2008/Fischer, Zwaan - Embodied language a review of the role of the motor system in language comprehension.pdf:pdf},
issn = {1747-0226},
journal = {Quarterly Journal of Experimental Psychology},
keywords = {embodied cognition,language processing,mirror neurons,motor resonance,perception and action},
month = {jun},
number = {6},
pages = {825--850},
pmid = {18470815},
title = {Embodied language: a review of the role of the motor system in language comprehension},
volume = {61},
year = {2008}
}
@article{Flanagan2003,
abstract = {Skilled motor behavior relies on the brain learning both to control the body and predict the consequences of this control. Prediction turns motor commands into expected sensory consequences [1], whereas control turns desired consequences into motor commands. To capture this symmetry, the neural processes underlying prediction and control are termed the forward and inverse internal models, respectively [2-5]. Here, we investigate how these two fundamental processes are related during motor learning. We used an object manipulation task in which subjects learned to move a hand-held object with novel dynamic properties along a prescribed path. We independently and simultaneously measured subjects' ability to control their actions and to predict their consequences. We found different time courses for predictor and controller learning, with prediction being learned far more rapidly than control. In early stages of manipulating the object, subjects could predict the consequences of their actions, as measured by the grip force they used to grasp the object, but could not generate appropriate actions for control, as measured by their hand trajectory. As predicted by several recent theoretical models of sensorimotor control [6-8], our results indicate that people can learn to predict the consequences of their actions before they can learn to control their actions.},
author = {Flanagan, Randall R. and Vetter, Philipp and Johansson, Roland S. and Wolpert, Daniel M},
doi = {10.1016/S0960-9822(03)00007-1},
file = {:Users/jhamrick/Dropbox/Papers/2003/Flanagan et al. - Prediction precedes control in motor learning.pdf:pdf},
isbn = {0960-9822},
issn = {09609822},
journal = {Current Biology},
number = {2},
pages = {146--150},
pmid = {12546789},
title = {Prediction precedes control in motor learning},
volume = {13},
year = {2003}
}
@article{Flusberg2011,
abstract = {Are objects that are more difficult to physically manipulate also more difficult to mentally manipulate? In our study, participants interacted with wooden objects modeled after the figures from Shepard and Metzler's (1971) classic mental rotation experiment. One pair of objects was easy to physically rotate while another pair was difficult. They then completed a standard mental rotation task on images of these objects. Participants were slower to mentally rotate objects that were harder to physically rotate when they engaged in motor imagery. Further, this cost accrued with increasing angles of rotation. We verified this was the result of motor imagery by showing that the costs can be eliminated by using a strictly visual imagery strategy (imagining the objects moving on their own). These results reveal a striking constraint imposed by our real-world motor experiences on mental imagery, and also demonstrate a way that we can overcome such constraints.},
author = {Flusberg, Stephen J and Boroditsky, Lera},
doi = {10.3758/s13423-010-0024-2},
file = {:Users/jhamrick/Dropbox/Papers/2011/Flusberg, Boroditsky - Are things that are hard to physically move also hard to imagine moving.pdf:pdf},
isbn = {1342301000242},
issn = {1531-5320},
journal = {Psychonomic Bulletin \& Review},
keywords = {embodiment,mental rotation,motor imagery,physical experience,visual imagery},
month = {feb},
number = {1},
pages = {158--164},
pmid = {21327358},
title = {Are things that are hard to physically move also hard to imagine moving?},
volume = {18},
year = {2011}
}
@article{Forbus2011,
abstract = {Qualitative modeling concerns the representations and reasoning that people use to understand continuous aspects of the world. Qualitative models formalize everyday notions of causality and provide accounts of how to ground symbolic, relational representations in perceptual processes. This article surveys the basic ideas of qualitative modeling and their applications from a cognitive science perspective. It describes the basic principles of qualitativemodeling, and a variety of qualitative representations that have been developed for quantities and for relationships between them, providing a kind of qualitative mathematics.Three ontological frameworks for organizing modeling knowledge (processes, components, and field) are summarized, along with research on automatically assembling models for particular tasks from such knowledge. Qualitative simulation and how it carves up time into meaningful units is discussed. We discuss several accounts of causal reasoning about dynamical systems, based on different choices of qualitative mathematics and ontology.Qualitative spatial reasoning is explored, both in terms of relational systems and visual reasoning. Applications of qualitative models of particular interest to cognitive scientists are described, including how they have been used to capture the expertise of scientists and engineers and how they have been used in education. Open questions and frontiers are also discussed, focusing on relationships between ideas developed in the qualitativemodeling community and other areas of cognitive science.},
author = {Forbus, Kenneth D},
doi = {10.1002/wcs.115},
file = {:Users/jhamrick/Dropbox/Papers/2011/Forbus - Qualitative modeling.pdf:pdf},
isbn = {9780444522115},
issn = {19395078},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
month = {jul},
number = {4},
pages = {374--391},
title = {Qualitative modeling},
url = {http://doi.wiley.com/10.1002/wcs.115},
volume = {2},
year = {2011}
}
@article{Freyd1984,
author = {Freyd, Jennifer J and Finke, Ronald A},
doi = {10.1037/0278-7393.10.1.126},
file = {:Users/jhamrick/Dropbox/Papers/1984/Freyd, Finke - Representational Momentum.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
number = {1},
pages = {126--132},
title = {Representational Momentum},
volume = {10},
year = {1984}
}
@article{Freyd1988,
author = {Freyd, Jennifer J and Pantzer, Teresa M and Cheng, Jeannette L},
doi = {dx.doi.org/10.1037/0096-3445.117.4.395},
file = {:Users/jhamrick/Dropbox/Papers/1988/Freyd, Pantzer, Cheng - Representing Statics as Forces in Equilibrium.pdf:pdf},
journal = {Journal of Experimental Psychology: General},
pages = {395--407},
title = {Representing Statics as Forces in Equilibrium},
volume = {117},
year = {1988}
}
@article{Gallese1998,
abstract = {A new class of visuomotor neuron has been recently discovered in the monkey’s premotor cortex: mirror neurons. These neurons respond both when a particular action is performed by the recorded monkey and when the same action, performed by another individual, is observed. Mirror neurons appear to form a cortical system matching observation and execution of goal-related motor actions. Experimental evidence suggests that a similar matching system also exists in humans. What might be the functional role of this matching system? One possible function is to enable an organism to detect certain mental states of observed conspecifics. This function might be part of, or a precursor to, a more general mind-reading ability. Two different accounts of mind- reading have been suggested. According to ‘theory theory’, mental states are represented as inferred posits of a naive theory. According to ‘simulation theory’, other people’s mental states are represented by adopting their perspective: by tracking or matching their states with resonant states of one’s own. The activity of mirror neurons, and the fact that observers undergo motor facilitation in the same muscular groups as those utilized by target agents, are findings that accord well with simulation theory but would not be predicted by theory theory.},
author = {Gallese, Vittorio and Goldman, Alvin I},
doi = {10.1016/S1364-6613(98)01262-5},
file = {:Users/jhamrick/Dropbox/Papers/1998/Gallese, Goldman - Mirror neurons and the simulation theory of mind-reading.pdf:pdf},
isbn = {1364-6613 (Print) 1364-6613 (Linking)},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
number = {12},
pages = {493--501},
pmid = {21227300},
title = {Mirror neurons and the simulation theory of mind-reading},
volume = {2},
year = {1998}
}
@article{Gendler2004,
abstract = {Contemplating imaginary scenarios that evoke certain sorts of quasi-sensory intuitions may bring us to new beliefs about contingent features of the natural world. These beliefs may be produced quasi-observationally; the presence of a mental image may play a crucial cognitive role in the formation of the belief in question. And this albeit fallible quasi-observational belief-forming mechanism may, in certain contexts, be suf- ficiently reliable to count as a source of justification. This sheds light on the central puzzle surrounding scientific thought experiment, which is how contemplation of an imaginary scenario can lead to new knowledge about contingent features of the natural world.},
author = {Gendler, Tamar Szabo},
doi = {10.1086/425239},
file = {:Users/jhamrick/Dropbox/Papers/2004/Gendler - Thought Experiments Rethought--and Reperceived.pdf:pdf},
journal = {Philosophy of Science},
pages = {1152--1163},
title = {Thought Experiments Rethought--and Reperceived},
volume = {71},
year = {2004}
}
@incollection{Geoffroy2014,
abstract = {Numerical optimal control (the approximation of an optimal trajectory us- ing numerical iterative algorithms) is a promising approach to compute the control of complex dynamical systems whose instantaneous linearization is not meaningful. Aside from the problems of computation cost, these methods raise several concep- tual problems, like stability, robustness, or simply understanding of the nature of the obtained solution. In this paper, we propose a rewriting of the Differential Dynamic Programing solver. Our variant is more efficient and numerically more interesting. Furthermore, it draws some interesting comparisons with the classical inverse for- mulation: in particular, we show that inverse kinematics can be seen as singular case of it, when the preview horizon collapses.},
author = {Geoffroy, Perle and Mansard, Nicolas and Raison, Maxime and Achiche, Sofiane and Tassa, Yuval and Todorov, Emanuel},
booktitle = {Advances in Robot Kinematics},
doi = {10.1007/978-3-319-06698-1},
file = {:Users/jhamrick/Dropbox/Papers/2014/Geoffroy et al. - From Inverse Kinematics to Optimal Control.pdf:pdf},
isbn = {978-3-319-06697-4},
keywords = {differential dynamic programming,inverse kinematics,optimal control},
pages = {409--418},
publisher = {Springer},
title = {From Inverse Kinematics to Optimal Control},
year = {2014}
}
@article{Goldman1992,
author = {Goldman, Alvin I},
doi = {10.1111/j.1468-0017.1992.tb00200.x},
file = {:Users/jhamrick/Dropbox/Papers/1992/Goldman - In Defense of the Simulation Theory.pdf:pdf},
journal = {Mind \& Language},
number = {1-2},
pages = {104--119},
title = {In Defense of the Simulation Theory},
volume = {7},
year = {1992}
}
@article{Goodman2011,
abstract = {The very early appearance of abstract knowledge is often taken as evidence for innateness. We explore the relative learning speeds of abstract and specific knowledge within a Bayesian framework and the role for innate structure. We focus on knowledge about causality, seen as a domain-general intuitive theory, and ask whether this knowledge can be learned from co-occurrence of events. We begin by phrasing the causal Bayes nets theory of causality and a range of alternatives in a logical language for relational theories. This allows us to explore simultaneous inductive learning of an abstract theory of causality and a causal model for each of several causal systems. We find that the correct theory of causality can be learned relatively quickly, often becoming available before specific causal theories have been learned--an effect we term the blessing of abstraction. We then explore the effect of providing a variety of auxiliary evidence and find that a collection of simple perceptual input analyzers can help to bootstrap abstract knowledge. Together, these results suggest that the most efficient route to causal knowledge may be to build in not an abstract notion of causality but a powerful inductive learning mechanism and a variety of perceptual supports. While these results are purely computational, they have implications for cognitive development, which we explore in the conclusion.},
author = {Goodman, Noah D and Ullman, Tomer D and Tenenbaum, Joshua B},
doi = {10.1037/a0021336},
file = {:Users/jhamrick/Dropbox/Papers/2011/Goodman, Ullman, Tenenbaum - Learning a theory of causality.pdf:pdf},
isbn = {0033-295X},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {1748,2008,believed that it was,blessing of abstraction,causality,constant conjunction of events,extract stable causal relations,follows,from the,hierarchical bayesian model,hume,innateness,learning,nativism,principle of association,probabilistic models,stream of experience,the,what allows people to},
month = {jan},
number = {1},
pages = {110--119},
pmid = {21244189},
title = {Learning a theory of causality.},
volume = {118},
year = {2011}
}
@article{Gopnik1992,
abstract = {... This view has variously been called a 'copy theory ' ( Wellman , 1990), a 'Cibsonian theory ' (Astington {\&} Gopnik , 1991a) a 'situation theory ' (Perner, 1991), or a 'cognitive connection' (Flavell, 1988) theory of belief. The similar idea in all these accounts is that belief contents Page 8. ...},
author = {Gopnik, Alison and Wellman, Henry M},
doi = {10.1111/j.1468-0017.1992.tb00202.x},
file = {:Users/jhamrick/Dropbox/Papers/1992/Gopnik, Wellman - Why the Child's Theory of Mind Really Is a Theory(2).pdf:pdf;:Users/jhamrick/Dropbox/Papers/1992/Gopnik, Wellman - Why the Child's Theory of Mind Really Is a Theory.pdf:pdf},
journal = {Mind \& Language},
number = {1-2},
pages = {145--171},
title = {Why the Child's Theory of Mind Really Is a Theory},
volume = {7},
year = {1992}
}
@article{Gordon1992,
author = {Gordon, Robert M},
doi = {10.1111/j.1468-0017.1992.tb00195.x},
file = {:Users/jhamrick/Dropbox/Papers/1992/Gordon - The Simulation theory Objections and misconceptions.pdf:pdf},
journal = {Mind \& Language},
number = {1-2},
pages = {11--34},
title = {The Simulation theory: Objections and misconceptions},
volume = {7},
year = {1992}
}
@article{Griffiths2010,
author = {Griffiths, Thomas L and Chater, Nick and Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1016/j.tics.2010.05.004},
file = {:Users/jhamrick/Dropbox/Papers/2010/Griffiths et al. - Probabilistic models of cognition exploring representations and inductive biases.pdf:pdf},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
number = {8},
pages = {357--364},
publisher = {Elsevier},
title = {Probabilistic models of cognition: exploring representations and inductive biases},
url = {http://dx.doi.org/10.1016/j.tics.2010.05.004 http://www.sciencedirect.com/science/article/pii/S1364661310001129 http://linkinghub.elsevier.com/retrieve/pii/S1364661310001129},
volume = {14},
year = {2010}
}
@article{Griffiths2015,
author = {Griffiths, Thomas L and Lieder, Falk and Goodman, Noah D},
doi = {10.1111/tops.12142},
file = {:Users/jhamrick/Dropbox/Papers/2015/Griffiths, Lieder, Goodman - Rational Use of Cognitive Resources Levels of Analysis Between the Computational and the Algorithmic.pdf:pdf},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {algorithmic level,bayesian models of cognition,computational,level,levels of analysis,rational process models,resource-rational models},
number = {2},
pages = {217--229},
title = {Rational Use of Cognitive Resources: Levels of Analysis Between the Computational and the Algorithmic},
url = {http://doi.wiley.com/10.1111/tops.12142},
volume = {7},
year = {2015}
}
@article{Griffiths2009,
author = {Griffiths, Thomas L and Tenenbaum, Joshua B},
doi = {10.1037/a0017201},
file = {:Users/jhamrick/Dropbox/Papers/2009/Griffiths, Tenenbaum - Theory-based causal induction.pdf:pdf},
issn = {1939-1471},
journal = {Psychological Review},
keywords = {1607,a set,and,bayesian modeling,causal induction,computing the orbits of,he noticed a surprising,in 1695,in newton,intuitive theories,of comets for inclusion,rational analysis,regularity,s principia mathematica when,sir edmond halley was,the comets of 1531},
number = {4},
pages = {661--716},
title = {Theory-based causal induction.},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0017201},
volume = {116},
year = {2009}
}
@article{Griffiths2006,
abstract = {Human perception and memory are often explained as optimal statistical inferences that are informed by accurate prior probabilities. In contrast, cognitive judgments are usually viewed as following error-prone heuristics that are insensitive to priors. We examined the optimality of human cognition in a more realistic context than typical laboratory studies, asking people to make predictions about the duration or extent of everyday phenomena such as human life spans and the box-office take of movies. Our results suggest that everyday cognitive judgments follow the same optimal statistical principles as perception and memory, and reveal a close correspondence between people's implicit probabilistic models and the statistics of the world.},
author = {Griffiths, Thomas L and Tenenbaum, Joshua B},
doi = {10.1111/j.1467-9280.2006.01780.x},
file = {:Users/jhamrick/Dropbox/Papers/2006/Griffiths, Tenenbaum - Optimal predictions in everyday cognition.pdf:pdf},
isbn = {0956-7976},
issn = {09567976},
journal = {Psychological Science},
number = {9},
pages = {767--773},
pmid = {16984293},
title = {Optimal predictions in everyday cognition},
volume = {17},
year = {2006}
}
@article{Grush2004,
abstract = {The emulation theory of representation is developed and explored as a framework that can revealingly synthesize a wide variety of representational functions of the brain. The framework is based on constructs from control theory (forward models) and signal processing (Kalman filters). The idea is that in addition to simply engaging with the body and environment, the brain constructs neural circuits that act as models of the body and environment. During overt sensorimotor engagement, these models are driven by efference copies in parallel with the body and environment, in order to provide expectations of the sensory feedback, and to enhance and process sensory information. These models can also be run off-line in order to produce imagery, estimate outcomes of different actions, and evaluate and develop motor plans. The framework is initially developed within the context of motor control, where it has been shown that inner models running in parallel with the body can reduce the effects of feedback delay problems. The same mechanisms can account for motor imagery as the off-line driving of the emulator via efference copies. The framework is extended to account for visual imagery as the off-line driving of an emulator of the motor-visual loop. I also show how such systems can provide for amodal spatial imagery. Perception, including visual perception, results from such models being used to form expectations of, and to interpret, sensory input. I close by briefly outlining other cognitive functions that might also be synthesized within this framework, including reasoning, theory of mind phenomena, and language.},
author = {Grush, Rick},
doi = {10.1017/S0140525X04000093},
file = {:Users/jhamrick/Dropbox/Papers/2004/Grush - The emulation theory of representation motor control, imagery, and perception.pdf:pdf},
isbn = {0140-525X},
issn = {0140-525X},
journal = {The Behavioral and Brain Sciences},
keywords = {Brain,Brain: physiology,Environment,Humans,Imagination,Language,Models, Theoretical,Perception,Psychomotor Performance,Psychomotor Performance: physiology,Psychophysiology,Visual Perception},
number = {3},
pages = {377--96; discussion 396--442},
pmid = {15736871},
title = {The emulation theory of representation: motor control, imagery, and perception.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15736871},
volume = {27},
year = {2004}
}
@article{Guendelman2003,
author = {Guendelman, Eran and Bridson, Robert and Fedkiw, Ronald},
doi = {10.1145/882262.882358},
file = {:Users/jhamrick/Dropbox/Papers/2003/Guendelman, Bridson, Fedkiw - Nonconvex Rigid Bodies with Stacking.pdf:pdf},
journal = {ACM Transactions on Graphics},
keywords = {1000 nonconvex rings,and each pole is,collision,contact,each ring is made,figure 1,friction,ing dropped onto a,made up of 880,nonconvex,rigid bodies,set of 25 poles,settling after be-,triangles,up of 320,with friction},
number = {3},
title = {Nonconvex Rigid Bodies with Stacking},
volume = {22},
year = {2003}
}
@article{Han2015,
author = {Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
file = {:Users/jhamrick/Dropbox/Papers/2015/Han, Levine, Abbeel - Learning Compound Multi-Step Controllers under Unknown Dynamics.pdf:pdf},
journal = {Proceedings of the 28th IEEE/RSJ International Conference on Intelligent Robots and Systems},
title = {Learning Compound Multi-Step Controllers under Unknown Dynamics},
url = {http://rll.berkeley.edu/reset_controller/reset_controller.pdf},
year = {2015}
}
@article{Hay2012,
abstract = {Sequential decision problems are often approximately solvable by simulating possible future action sequences. {\em Metalevel} decision procedures have been developed for selecting {\em which} action sequences to simulate, based on estimating the expected improvement in decision quality that would result from any particular simulation; an example is the recent work on using bandit algorithms to control Monte Carlo tree search in the game of Go. In this paper we develop a theoretical basis for metalevel decisions in the statistical framework of Bayesian {\em selection problems}, arguing (as others have done) that this is more appropriate than the bandit framework. We derive a number of basic results applicable to Monte Carlo selection problems, including the first finite sampling bounds for optimal policies in certain cases; we also provide a simple counterexample to the intuitive conjecture that an optimal policy will necessarily reach a decision in all cases. We then derive heuristic approximations in both Bayesian and distribution-free settings and demonstrate their superiority to bandit-based heuristics in one-shot decision problems and in Go.},
archivePrefix = {arXiv},
arxivId = {1207.5879},
author = {Hay, Nicholas J and Russell, Stuart J and Tolpin, David and Shimony, Solomon Eyal},
eprint = {1207.5879},
file = {:Users/jhamrick/Dropbox/Papers/2012/Hay et al. - Selecting Computations Theory and Applications.pdf:pdf},
journal = {arXiv preprint arXiv:1207.5878v1 [cs.AI]},
title = {Selecting Computations: Theory and Applications},
url = {http://arxiv.org/abs/1207.5879},
year = {2012}
}
@article{Hegarty2004,
abstract = {Recent studies have provided evidence for mental simulation as a strategy in mechanical reasoning. This type of reasoning can be dissociated from reasoning based on descriptive knowledge in that it depends on different abilities and memory stores, is expressed more easily in gesture than in language, exhibits analog properties, and can result in correct inferences in situations where people do not have correct descriptive knowledge. Although it is frequently accompanied by imagery, mental simulation is not a process of inspecting a holistic visual image in the 'mind's eye'. Mental simulations are constructed piecemeal, include representations of non-visible properties and can be used in conjunction with non-imagery processes, such as task decomposition and rule-based reasoning.},
author = {Hegarty, Mary},
doi = {10.1016/j.tics.2004.04.001},
file = {:Users/jhamrick/Dropbox/Papers/2004/Hegarty - Mechanical reasoning by mental simulation.pdf:pdf},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
month = {jun},
number = {6},
pages = {280--285},
pmid = {15165554},
title = {Mechanical reasoning by mental simulation},
volume = {8},
year = {2004}
}
@article{Hubbard2005,
abstract = {Memory for the final location of a moving target is often displaced in the direction of target motion, and this has been referred to as representational momentum. Characteristics of the target (e.g., velocity, size, direction, and identity), display (e.g., target format, retention interval, and response method), context (landmarks, expectations, and attribution of motion source), and observer (e.g., allocation of attention, eye movements, and psychopathology) that influence the direction and magnitude of displacement are reviewed. Specific conclusions regarding numerous variables that influence displacement (e.g., presence of landmarks or surrounding context), as well as broad-based conclusions regarding displacement in general (e.g., displacement does not reflect objective physical principles, may reflect aspects of naive physics, does not solely reflect eye movements, may involve some modular processing, and reflects high-level processes) are drawn. A possible computational theory of displacement is suggested in which displacement (1) helps bridge the gap between perception and action and (2) plays a critical part in localizing stimuli in the environment.},
author = {Hubbard, Timothy L},
doi = {10.3758/BF03196775},
file = {:Users/jhamrick/Dropbox/Papers/2005/Hubbard - Representational momentum and related displacements in spatial memory A review of the findings.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic Bulletin \& Review},
number = {5},
pages = {822--851},
pmid = {16524000},
title = {Representational momentum and related displacements in spatial memory: A review of the findings.},
volume = {12},
year = {2005}
}
@article{Jacobs2011,
author = {Jacobs, Robert A. and Kruschke, John K.},
doi = {10.1002/wcs.80},
file = {:Users/jhamrick/Dropbox/Papers/2011/Jacobs, Kruschke - Bayesian learning theory applied to human cognition.pdf:pdf},
issn = {19395078},
journal = {Wiley Interdisciplinary Reviews: Cognitive Science},
number = {1},
pages = {8--21},
title = {{Bayesian} learning theory applied to human cognition},
volume = {2},
year = {2011}
}
@incollection{Johnson-Laird2012,
author = {Johnson-Laird, Philip N},
booktitle = {The Oxford Handbook of Thinking and Reasoning},
doi = {10.1093/oxfordhb/9780199734689.001.0001},
file = {:Users/jhamrick/Dropbox/Papers/2012/Johnson-Laird - Inference with Mental Models.pdf:pdf},
isbn = {9780199734689},
pages = {134--145},
title = {Inference with Mental Models},
year = {2012}
}
@article{Jones2011,
abstract = {The prominence of Bayesian modeling of cognition has increased recently largely because of mathematical advances in specifying and deriving predictions from complex probabilistic models. Much of this research aims to demonstrate that cognitive behavior can be explained from rational principles alone, without recourse to psychological or neurological processes and representations. We note commonalities between this rational approach and other movements in psychology - namely, Behaviorism and evolutionary psychology - that set aside mechanistic explanations or make use of optimality assumptions. Through these comparisons, we identify a number of challenges that limit the rational program's potential contribution to psychological theory. Specifically, rational Bayesian models are significantly unconstrained, both because they are uninformed by a wide range of process-level data and because their assumptions about the environment are generally not grounded in empirical measurement. The psychological implications of most Bayesian models are also unclear. Bayesian inference itself is conceptually trivial, but strong assumptions are often embedded in the hypothesis sets and the approximation algorithms used to derive model predictions, without a clear delineation between psychological commitments and implementational details. Comparing multiple Bayesian models of the same task is rare, as is the realization that many Bayesian models recapitulate existing (mechanistic level) theories. Despite the expressive power of current Bayesian models, we argue they must be developed in conjunction with mechanistic considerations to offer substantive explanations of cognition. We lay out several means for such an integration, which take into account the representations on which Bayesian inference operates, as well as the algorithms and heuristics that carry it out. We argue this unification will better facilitate lasting contributions to psychological theory, avoiding the pitfalls that have plagued previous theoretical movements.},
author = {Jones, Matt and Love, Bradley C},
doi = {10.1017/S0140525X10003134},
file = {:Users/jhamrick/Dropbox/Papers/2011/Jones, Love - Bayesian fundamentalism or enlightenment On the explanatory status and theoretical contributions of Bayesian models of cog.pdf:pdf},
journal = {The Behavioral and Brain Sciences},
keywords = {bayesian modeling,cognitive processing,levels of analysis,rational analysis,representation},
number = {4},
pages = {169--188},
title = {{Bayesian} fundamentalism or enlightenment? {On} the explanatory status and theoretical contributions of Bayesian models of cognition.},
volume = {34},
year = {2011}
}
@article{Just1976,
author = {Just, Marcel Adam and Carpenter, Patricia A},
doi = {10.1016/0010-0285(76)90015-3},
file = {:Users/jhamrick/Dropbox/Papers/1976/Just, Carpenter - Eye fixations and cognitive processes.pdf:pdf},
journal = {Cognitive Psychology},
pages = {441--480},
title = {Eye fixations and cognitive processes},
volume = {8},
year = {1976}
}
@article{Kahneman1973,
abstract = {Teil von Judgment under Uncertainty: Heuristics and Biases (Kahneman, Slovic, Tversky 1982)},
author = {Kahneman, Daniel and Tversky, Amos},
doi = {10.1037/h0034747},
file = {:Users/jhamrick/Dropbox/Papers/1973/Kahneman, Tversky - On the psychology of prediction.pdf:pdf},
isbn = {0033-295X\r1939-1471},
issn = {0033-295X},
journal = {Psychological Review},
number = {4},
pages = {237--251},
pmid = {6571423},
title = {On the psychology of prediction.},
url = {http://psycnet.apa.org/journals/rev/80/4/237.pdf},
volume = {80},
year = {1973}
}
@techreport{Kahneman1981,
author = {Kahneman, Daniel and Tversky, Amos},
file = {:Users/jhamrick/Dropbox/Papers/1981/Kahneman, Tversky - The simulation heuristic.pdf:pdf},
title = {The simulation heuristic},
url = {http://www.dtic.mil/cgi-bin/GetTRDoc?AD=ADA099504},
year = {1981}
}
@article{Kawato1999,
abstract = {A number of internal model concepts are now widespread in neuroscience\nand cognitive science. These concepts are supported by behavioral,\nneurophysiological, and imaging data; furthermore, these models have\nhad their structures and functions revealed by such data. In particular,\na specific theory on inverse dynamics model learning is directly\nsupported by unit recordings from cerebellar Purkinje cells. Multiple\npaired forward inverse models describing how diverse objects and\nenvironments can be controlled and learned separately have recently\nbeen proposed. The 'minimum variance model' is another major recent\nadvance in the computational theory of motor control. This model\nintegrates two furiously disputed approaches on trajectory planning,\nstrongly suggesting that both kinematic and dynamic internal models\nare utilized in movement planning and control.},
author = {Kawato, M},
doi = {10.1016/S0959-4388(99)00028-8},
file = {:Users/jhamrick/Dropbox/Papers/1999/Kawato - Internal models for motor control and trajectory planning.pdf:pdf},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinions in Neurobiology},
keywords = {Animals,Brain,Humans,Models,Motor Activity,Neurological,Psychomotor Performance,physiology},
number = {6},
pages = {718--727},
pmid = {10607637},
title = {Internal models for motor control and trajectory planning.},
volume = {9},
year = {1999}
}
@article{Kemp2010a,
abstract = {Learning to understand a single causal system can be an achievement, but humans must learn about multiple causal systems over the course of a lifetime. We present a hierarchical Bayesian framework that helps to explain how learning about several causal systems can accelerate learning about systems that are subsequently encountered. Given experience with a set of objects, our framework learns a causal model for each object and a causal schema that captures commonalities among these causal models. The schema organizes the objects into categories and specifies the causal powers and characteristic features of these categories and the characteristic causal interactions between categories. A schema of this kind allows causal models for subsequent objects to be rapidly learned, and we explore this accelerated learning in four experiments. Our results confirm that humans learn rapidly about the causal powers of novel objects, and we show that our framework accounts better for our data than alternative models of causal learning.},
author = {Kemp, Charles and Goodman, Noah D and Tenenbaum, Joshua B},
doi = {10.1111/j.1551-6709.2010.01128.x},
file = {:Users/jhamrick/Dropbox/Papers/2010/Kemp, Goodman, Tenenbaum - Learning to Learn Causal Models.pdf:pdf},
isbn = {0364-0213},
issn = {03640213},
journal = {Cognitive Science},
keywords = {1,categorization,causal learning,children face a seemingly,course of,endless stream of inductive,hierarchical bayesian models,learning inductive constraints,learning tasks over the,learning to learn,learning to learn causal,models,transfer learning},
number = {7},
pages = {1185--1243},
pmid = {21564248},
title = {Learning to Learn Causal Models},
volume = {34},
year = {2010}
}
@article{Kemp2007,
abstract = {Inductive learning is impossible without overhypotheses, or constraints on the hypotheses considered by the learner. Some of these overhypotheses must be innate, but we suggest that hierarchical Bayesian models can help to explain how the rest are acquired. To illustrate this claim, we develop models that acquire two kinds of overhypotheses--overhypotheses about feature variability (e.g. the shape bias in word learning) and overhypotheses about the grouping of categories into ontological kinds like objects and substances.},
author = {Kemp, Charles and Perfors, Amy and Tenenbaum, Joshua B},
doi = {10.1111/j.1467-7687.2007.00585.x},
file = {:Users/jhamrick/Dropbox/Papers/2007/Kemp, Perfors, Tenenbaum - Learning overhypotheses with hierarchical Bayesian models.pdf:pdf},
isbn = {1363-755X (Print)},
issn = {1363-755X},
journal = {Developmental Science},
month = {may},
number = {3},
pages = {307--321},
pmid = {17444972},
title = {Learning overhypotheses with hierarchical {Bayesian} models.},
volume = {10},
year = {2007}
}
@article{Kemp2008,
abstract = {Algorithms for finding structure in data have become increasingly important both as tools for scientific data analysis and as models of human learning, yet they suffer from a critical limitation. Scientists discover qualitatively new forms of structure in observed data: For instance, Linnaeus recognized the hierarchical organization of biological species, and Mendeleev recognized the periodic structure of the chemical elements. Analogous insights play a pivotal role in cognitive development: Children discover that object category labels can be organized into hierarchies, friendship networks are organized into cliques, and comparative relations (e.g., "bigger than" or "better than") respect a transitive order. Standard algorithms, however, can only learn structures of a single form that must be specified in advance: For instance, algorithms for hierarchical clustering create tree structures, whereas algorithms for dimensionality-reduction create low-dimensional spaces. Here, we present a computational model that learns structures of many different forms and that discovers which form is best for a given dataset. The model makes probabilistic inferences over a space of graph grammars representing trees, linear orders, multidimensional spaces, rings, dominance hierarchies, cliques, and other forms and successfully discovers the underlying structure of a variety of physical, biological, and social domains. Our approach brings structure learning methods closer to human abilities and may lead to a deeper computational understanding of cognitive development.},
author = {Kemp, Charles and Tenenbaum, Joshua B},
doi = {10.1073/pnas.0802631105},
file = {:Users/jhamrick/Dropbox/Papers/2008/Kemp, Tenenbaum - The discovery of structural form.pdf:pdf},
isbn = {1091-6490 (Electronic)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Algorithms,Data Interpretation,Humans,Learning,Learning: physiology,Models,Research Design,Statistical,Theoretical},
number = {31},
pages = {10687--92},
pmid = {18669663},
title = {The discovery of structural form},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18669663},
volume = {105},
year = {2008}
}
@article{Kemp2010,
abstract = {Concept learning is challenging in part because the meanings of many concepts depend on their relationships to other concepts. Learning these concepts in isolation can be difficult, but we present a model that discovers entire systems of related concepts. These systems can be viewed as simple theories that specify the concepts that exist in a domain, and the laws or principles that relate these concepts. We apply our model to several real-world problems, including learning the structure of kinship systems and learning ontologies. We also compare its predictions to data collected in two behavioral experiments. Experiment 1 shows that our model helps to explain how simple theories are acquired and used for inductive inference. Experiment 2 suggests that our model provides a better account of theory discovery than a more traditional alternative that focuses on features rather than relations.},
author = {Kemp, Charles and Tenenbaum, Joshua B and Niyogi, Sourabh and Griffiths, Thomas L},
doi = {10.1016/j.cognition.2009.09.003},
file = {:Users/jhamrick/Dropbox/Papers/2010/Kemp et al. - A probabilistic model of theory formation.pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {bayesian modeling,conceptual structure,relational learning,systems of concepts},
month = {feb},
number = {2},
pages = {165--196},
pmid = {19892328},
publisher = {Elsevier B.V.},
title = {A probabilistic model of theory formation},
volume = {114},
year = {2010}
}
@article{Khemlani2013,
abstract = {We present a theory, and its computer implementation, of how mental simulations underlie the abductions of informal algorithms and deductions from these algorithms. Three experiments tested the theory's predictions, using an environment of a single railway track and a siding. This environment is akin to a universal Turing machine, but it is simple enough for nonprogrammers to use. Participants solved problems that required use of the siding to rearrange the order of cars in a train (experiment 1). Participants abduced and described in their own words algorithms that solved such problems for trains of any length, and, as the use of simulation predicts, they favored "while-loops" over "for-loops" in their descriptions (experiment 2). Given descriptions of loops of procedures, participants deduced the consequences for given trains of six cars, doing so without access to the railway environment (experiment 3). As the theory predicts, difficulty in rearranging trains depends on the numbers of moves and cars to be moved, whereas in formulating an algorithm and deducing its consequences, it depends on the Kolmogorov complexity of the algorithm. Overall, the results corroborated the use of a kinematic mental model in creating and testing informal algorithms and showed that individuals differ reliably in the ability to carry out these tasks.},
author = {Khemlani, Sangeet Suresh and Mackiewicz, Robert and Bucciarelli, Monica and Johnson-Laird, Philip N},
doi = {10.1073/pnas.1316275110},
file = {:Users/jhamrick/Dropbox/Papers/2013/Khemlani et al. - Kinematic mental simulations in abduction and deduction.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adolescent,Adult,Algorithms,Biomechanical Phenomena,Female,Humans,Male,Models,Neurological,Problem Solving,Problem Solving: physiology},
number = {42},
pages = {16766--71},
pmid = {24082090},
title = {Kinematic mental simulations in abduction and deduction.},
volume = {110},
year = {2013}
}
@article{Kitaev2015,
author = {Kitaev, Nikita and Abbeel, Pieter},
file = {:Users/jhamrick/Dropbox/Papers/2015/Kitaev, Abbeel - Physics-Based Trajectory Optimization for Grasping in Cluttered Environments.pdf:pdf},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
title = {Physics-Based Trajectory Optimization for Grasping in Cluttered Environments},
url = {http://www.eecs.berkeley.edu/~pabbeel/papers/2015-ICRA-clutter.pdf},
year = {2015}
}
@article{Kording2004,
abstract = {When we learn a new motor skill, such as playing an approaching tennis ball, both our sensors and the task possess variability. Our sensors provide imperfect information about the ball’s velocity, so we can only estimate it. Combining information from multiple modalities can reduce the error in this estimate1–4. On a longer time scale, not all velocities are a priori equally probable, and over the course of a match there will be a probability distribution of velocities. According to bayesian theory5,6, an optimal estimate results from combining information about the distribution of velocities—the prior—with evidence from sensory feedback. As uncertainty increases, when playing in fog or at dusk, the system should increasingly rely on prior knowledge. To use a bayesian strategy, the brain would need to represent the prior distribution and the level of uncertainty in the sensory feedback. Here we control the statistical variations of a new sensorimotor task and manipulate the uncertainty of the sensory feedback. We show that subjects internally represent both the statistical distribution of the task and their sensory uncertainty, combining them in a manner consistent with a performance-optimizing bayesian process4,5. The central nervous system therefore employs probabilistic models during sensorimotor learning.},
author = {K{\"{o}}rding, Konrad P and Wolpert, Daniel M},
doi = {10.1038/nature02169},
file = {:Users/jhamrick/Dropbox/Papers/2004/K{\"{o}}rding, Wolpert - Bayesian integration in sensorimotor learning.pdf:pdf},
isbn = {0028-0836},
issn = {0028-0836},
journal = {Nature},
number = {6971},
pages = {244--247},
pmid = {14724638},
title = {{Bayesian} integration in sensorimotor learning},
volume = {427},
year = {2004}
}
@article{Kosslyn1988,
author = {Kosslyn, Stephen M},
file = {:Users/jhamrick/Dropbox/Papers/1988/Kosslyn - Aspect of a Cognitive Neuroscience of Mental Imagery.pdf:pdf},
journal = {Science},
number = {4859},
pages = {1621--1626},
title = {Aspect of a Cognitive Neuroscience of Mental Imagery},
url = {http://www.jstor.org/stable/1701012},
volume = {240},
year = {1988}
}
@article{Kuipers1986,
author = {Kuipers, Benjamin},
doi = {10.1016/0004-3702(86)90073-1},
file = {:Users/jhamrick/Dropbox/Papers/1986/Kuipers - Qualitative Simulation.pdf:pdf},
journal = {Artificial Intelligence},
number = {3},
pages = {289--338},
title = {Qualitative Simulation},
volume = {29},
year = {1986}
}
@article{Lee2015,
abstract = {Manipulation of deformable objects often requires a robot to apply specific forces to bring the object into the desired configuration. For instance, tightening a knot requires pulling on the ends, flattening an article of clothing requires smoothing out wrinkles, and erasing a whiteboard requires applying downward pressure. We present a method for learn- ing force-based manipulation skills from demonstrations. Our approach uses non-rigid registration to compute a warping function that transforms both the end-effector poses and forces in each demonstration into the current scene, based on the configuration of the object. Our method then uses the variation between the demonstrations to extract a single trajectory, along with time-varying feedback gains that determine how much to match poses or forces. This results in a learned variable- impedance control strategy that trades off force and position errors, providing for the right level of compliance that applies the necessary forces at each stage of the motion. We evaluate our approach by tying knots in rope, flattening towels, and erasing a whiteboard.},
author = {Lee, Alex X and Lu, Henry and Gupta, Abhishek and Levine, Sergey and Abbeel, Pieter},
doi = {10.1109/ICRA.2015.7138997},
file = {:Users/jhamrick/Dropbox/Papers/2015/Lee et al. - Learning Force-Based Manipulation of Deformable Objects from Multiple Demonstrations.pdf:pdf},
issn = {10504729},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
title = {Learning Force-Based Manipulation of Deformable Objects from Multiple Demonstrations},
year = {2015}
}
@article{Burnin,
author = {Lieder, Falk and Griffiths, Thomas L and Goodman, Noah D},
file = {:Users/jhamrick/Dropbox/Papers/2012/Lieder, Griffiths, Goodman - Burn-in, bias, and the rationality of anchoring.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
title = {Burn-in, bias, and the rationality of anchoring},
url = {http://papers.nips.cc/paper/4719-burn-in-bias-and-the-rationality-of-anchoring},
volume = {25},
year = {2012}
}
@article{Marcus2013,
author = {Marcus, Gary F and Davis, Ernest},
doi = {10.1177/0956797613495418},
file = {:Users/jhamrick/Dropbox/Papers/2013/Marcus, Davis - How Robust Are Probabilistic Models of Higher-Level Cognition.pdf:pdf;:Users/jhamrick/Dropbox/Papers/2013/Marcus, Davis - How Robust Are Probabilistic Models of Higher-Level Cognition(2).pdf:pdf},
issn = {0956-7976},
journal = {Psychological Science},
keywords = {13,27,8,bayesian models,be seen as an,cognition,engine of proba-,optimality,received 1,revision accepted 5,s,should the human mind},
number = {12},
pages = {2351--2360},
title = {How Robust Are Probabilistic Models of Higher-Level Cognition?},
url = {http://pss.sagepub.com/lookup/doi/10.1177/0956797613495418},
volume = {24},
year = {2013}
}
@incollection{Marr1971,
author = {Marr, David},
booktitle = {Vision},
chapter = {1},
file = {:Users/jhamrick/Dropbox/Papers/1971/Marr - The Philosophy and the Approach.pdf:pdf},
isbn = {9780262514620},
title = {The Philosophy and the Approach},
url = {http://web.stanford.edu/class/psych209a/ReadingsByDate/01_07/Marr82Philosophy.pdf},
year = {1971}
}
@article{Matlock2004,
abstract = {Sentences such as The road runs through the valley and The mountain range goes from Canada to Mexico include a motion verb but express no explicit motion or state change. It is argued that these sentences involve fictive motion, an implicit type of motion. But do people trying to understand these sentences mentally simulate motion? This question was addressed in four experiments. In each, participants read a story about travel--for instance, fast versus slow, short versus long distance, and easy versus difficult terrain--and then made a timed decision about a fictive motion sentence. Overall, latencies were shorter after they had read about fast travel, short distances, and easy terrains. Critically, the effect did not arise with nonfictive motion target sentences (e.g., The road is in the valley), as was demonstrated in three control studies. The results suggest that the processing of fictive motion includes mental simulation.},
author = {Matlock, Teenie},
doi = {10.3758/BF03206329},
file = {:Users/jhamrick/Dropbox/Papers/2004/Matlock - Fictive motion as cognitive simulation.pdf:pdf},
isbn = {0090-502X},
issn = {0090-502X},
journal = {Memory \& Cognition},
number = {8},
pages = {1389--1400},
pmid = {15900932},
title = {Fictive motion as cognitive simulation.},
volume = {32},
year = {2004}
}
@article{Mordatch2010,
abstract = {This paper presents a physics-based locomotion controller based on online planning. At each time-step, a planner optimizes locomotion over multiple phases of gait. Stance dynamics are modeled using a simplified Spring-Load Inverted (SLIP) model, while flight dynamics are modeled using projectile motion equations. Full-body control at each instant is optimized to match the instantaneous plan values, while also maintaining balance. Different types of gaits, including walking, running, and jumping, emerge automatically, as do transitions between different gaits. The controllers can traverse challenging terrain and withstand large external disturbances, while following high-level user commands at interactive rates.},
author = {Mordatch, Igor and de Lasa, Martin and Hertzmann, Aaron},
doi = {10.1145/1778765.1778808},
file = {:Users/jhamrick/Dropbox/Papers/2010/Mordatch, de Lasa, Hertzmann - Robust physics-based locomotion using low-dimensional planning.pdf:pdf},
isbn = {978-1-4503-0210-4},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {completion,control,foot,in these situations,jointly selected to set,locomotion,margin for error,of travel must be,physics-based animation,regular terrain with little,step locations and modes,this is especially important,when moving across ir-},
number = {4},
title = {Robust physics-based locomotion using low-dimensional planning},
url = {http://portal.acm.org/citation.cfm?doid=1778765.1778808},
volume = {29},
year = {2010}
}
@article{Mozer2008,
abstract = {Griffiths and Tenenbaum (2006) asked individuals to make predictions about the duration or extent of everyday events (e.g., cake baking times), and reported that predictions were optimal, employing Bayesian inference based on veridical prior distributions. Although the predictions conformed strikingly to statistics of the world, they reflect averages over many individuals. On the conjecture that the accuracy of the group response is chiefly a consequence of aggregating across individuals, we constructed simple, heuristic approximations to the Bayesian model premised on the hypothesis that individuals have access merely to a sample of k instances drawn from the relevant distribution. The accuracy of the group response reported by Griffiths and Tenenbaum could be accounted for by supposing that individuals each utilize only two instances. Moreover, the variability of the group data is more consistent with this small-sample hypothesis than with the hypothesis that people utilize veridical or nearly veridical representations of the underlying prior distributions. Our analyses lead to a qualitatively different view of how individuals reason from past experience than the view espoused by Griffiths and Tenenbaum.},
author = {Mozer, Michael C and Pashler, Harold and Homaei, Hadjar},
file = {:Users/jhamrick/Dropbox/Papers/2008/Mozer, Pashler, Homaei - Optimal predictions in everyday cognition the wisdom of individuals or crowds.pdf:pdf},
journal = {Cognitive Science},
keywords = {bayesian models,everyday reasoning,instance-,normative models,wisdom of crowds},
number = {7},
pages = {1133--1147},
title = {Optimal predictions in everyday cognition: the wisdom of individuals or crowds?},
url = {http://onlinelibrary.wiley.com/doi/10.1080/03640210802353016/abstract},
volume = {32},
year = {2008}
}
@article{Muller2003,
abstract = {Realistically animated fluids can add substantial realism to interactive applications such as virtual surgery simulators or computer games. In this paper we propose an interactive method based on Smoothed Particle Hydrodynamics (SPH) to simulate fluids with free surfaces. The method is an extension of the SPH-based technique by Desbrun to animate highly deformable bodies. We gear the method towards fluid simulation by deriving the force density fields directly from the Navier-Stokes equation and by adding a term to model surface tension effects. In contrast to Eulerian grid-based approaches, the particle-based approach makes mass conservation equations and convection terms dispensable which reduces the complexity of the simulation. In addition, the particles can directly be used to render the surface of the fluid. We propose methods to track and visualize the free surface using point splatting and marching cubes-based surface reconstruction. Our animation method is fast enough to be used in interactive systems and to allow for user interaction with models consisting of up to 5000 particles.},
author = {M{\"{u}}ller, Matthias and Charypar, David and Gross, Markus},
file = {:Users/jhamrick/Dropbox/Papers/2003/M{\"{u}}ller, Charypar, Gross - Particle-Based Fluid Simulation for Interactive Applications.pdf:pdf},
journal = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
number = {5},
title = {Particle-Based Fluid Simulation for Interactive Applications},
url = {http://dl.acm.org/citation.cfm?id=846298},
year = {2003}
}
@article{Muller2002,
abstract = {The linear strain measures that are commonly used in real-time animations of deformable objects yield fast and stable simulations. However; they are not suitable for large deformations. Recently; more realistic results have been achieved in computer graphics by using Green's non-linear strain tensor; but the non-linearity makes the simulation more costly and introduces numerical problems.In this paper; we present a new simulation technique that is stable and fast like linear models; but without the disturbing artifacts that occur with large deformations. As a precomputation step; a linear stiffness matrix is computed for the system. At every time step of the simulation; we compute a tensor field that describes the local rotations of all the vertices in the mesh. This field allows us to compute the elastic forces in a non-rotated reference frame while using the precomputed stiffness matrix. The method can be applied to both finite element models and mass-spring systems. Our approach provides robustness; speed; and a realistic appearance in the simulation of large deformations.},
author = {M{\"{u}}ller, Matthias and Dorsey, Julie and McMillan, L},
doi = {10.1145/545261.545269},
file = {:Users/jhamrick/Dropbox/Papers/2002/M{\"{u}}ller, Dorsey, McMillan - Stable Real-time Deformations.pdf:pdf},
isbn = {1581135734},
journal = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
keywords = {elasticity,finite elements,large deformations,physically based animation,stiffness warping},
title = {Stable Real-time Deformations},
url = {http://dl.acm.org/citation.cfm?id=545269},
year = {2002}
}
@incollection{Neal2011,
abstract = {Hamiltonian dynamics can be used to produce distant proposals for the Metropolis algorithm, thereby avoiding the slow exploration of the state space that results from the diffusive behaviour of simple random-walk proposals. Though originating in physics, Hamiltonian dynamics can be applied to most problems with continuous state spaces by simply introducing fictitious "momentum" variables. A key to its usefulness is that Hamiltonian dynamics preserves volume, and its trajectories can thus be used to define complex mappings without the need to account for a hard-to-compute Jacobian factor - a property that can be exactly maintained even when the dynamics is approximated by discretizing time. In this review, I discuss theoretical and practical aspects of Hamiltonian Monte Carlo, and present some of its variations, including using windows of states for deciding on acceptance or rejection, computing trajectories using fast approximations, tempering during the course of a trajectory to handle isolated modes, and short-cut methods that prevent useless trajectories from taking much computation time.},
archivePrefix = {arXiv},
arxivId = {1206.1901},
author = {Neal, Radford M},
booktitle = {Handbook of {Markov} Chain {Monte Carlo}},
chapter = {5},
editor = {Brooks, Steve and Gelman, Andrew and Jones, Galin and Meng, Xiao-Li},
eprint = {1206.1901},
file = {:Users/jhamrick/Dropbox/Papers/2011/Neal - MCMC using Hamiltonian dynamics.pdf:pdf},
publisher = {Chapman \& Hall},
title = {{MCMC} using {Hamiltonian} dynamics},
url = {http://arxiv.org/abs/1206.1901},
year = {2011}
}
@article{Neal2003,
author = {Neal, Radford M},
file = {:Users/jhamrick/Dropbox/Papers/2003/Neal - Slice Sampling(2).pdf:pdf;:Users/jhamrick/Dropbox/Papers/2003/Neal - Slice Sampling.pdf:pdf},
journal = {The Annals of Statistics},
number = {3},
pages = {705--767},
title = {Slice Sampling},
url = {http://www.jstor.org/stable/3448413},
volume = {31},
year = {2003}
}
@article{Nealen2006,
abstract = {Physically based deformable models have been widely embraced by the Computer Graphics community. Many problems outlined in a previous survey by Gibson and Mirtich have been addressed, thereby making these models interesting and useful for both offline and real-time applications, such as motion pictures and video games. In this paper, we present the most significant contributions of the past decade, which produce such impressive and perceivably realistic animations and simulations: finite element/difference/volume methods, mass-spring systems, mesh-free methods, coupled particle systems and reduced deformable models-based on modal analysis. For completeness, we also make a connection to the simulation of other continua, such as fluids, gases and melting objects. Since time integration is inherent to all simulated phenomena, the general notion of time discretization is treated separately, while specifics are left to the respective models. Finally, we discuss areas of application, such as elastoplastic deformation and fracture, cloth and hair animation, virtual surgery simulation, interactive entertainment and fluid/smoke animation, and also suggest areas for future research.},
author = {Nealen, Andrew and M{\"{u}}ller, Matthias and Keiser, Richard and Boxerman, Eddy and Carlson, Mark},
doi = {10.1111/j.1467-8659.2006.01000.x},
file = {:Users/jhamrick/Dropbox/Papers/2006/Nealen et al. - Physically based deformable models in computer graphics.pdf:pdf},
isbn = {1467-8659},
issn = {01677055},
journal = {Computer Graphics Forum},
keywords = {Continuum elasticity,Deformation,FEM,Fluid animation,Mass-spring,Mesh-free methods,Modal analysis,Physically based animation,Time integration},
number = {4},
pages = {809--836},
pmid = {1279},
title = {Physically based deformable models in computer graphics},
volume = {25},
year = {2006}
}
@article{Nguyen-Tuong2011,
abstract = {Models are among the most essential tools in robotics, such as kinematics and dynamics models of the robot’s own body and controllable external objects. It is widely believed that intelligent mammals also rely on internal models in order to generate their actions. However, while classical robotics relies on manually generated models that are based on human insights into physics, future autonomous, cognitive robots need to be able to automatically generate models that are based on information which is extracted from the data streams accessible to the robot. In this paper, we survey the progress in model learning with a strong focus on robot control on a kinematic as well as dynamical level. Here, a model describes essential information about the behavior of the environment and the influence of an agent on this environment. In the context of model based learning control, we view the model from three different perspectives. First, we need to study the different possible model learning architectures for robotics. Second, we discuss what kind of problems these architecture and the domain of robotics imply for the applicable learning methods. From this discussion, we deduce future directions of real-time learning algorithms. Third, we show where these scenarios have been used successfully in several case studies.},
author = {Nguyen-Tuong, Duy and Peters, Jan},
journal = {Cognitive Processing},
doi = {10.1007/s10339-011-0404-1},
file = {:Users/jhamrick/Dropbox/Papers/2011/Nguyen-Tuong, Peters - Model Learning for Robot Control A Survey.pdf:pdf},
isbn = {3405062780},
issn = {1612-4790},
keywords = {machine learning,model learning,regression,robot control},
pages = {319--340},
pmid = {21487784},
title = {Model Learning for Robot Control: A Survey},
volume = {12},
year = {2011}
}
@article{Paraschos2015,
author = {Paraschos, Alexandros and Rueckert, Elmar and Peters, Jan and Neumann, Gerhard},
file = {:Users/jhamrick/Dropbox/Papers/2015/Paraschos et al. - Model-Free Probabilistic Movement Primitives for Physical Interaction.pdf:pdf},
journal = {Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems},
title = {Model-Free Probabilistic Movement Primitives for Physical Interaction},
url = {http://www.ausy.tu-darmstadt.de/uploads/Team/PubAlexParaschos/Paraschos_IROS_2015.pdf},
year = {2015}
}
@article{Parsons1994,
abstract = {Related perceptual, motor, and cognitive performances were examined to reveal the accuracy of the properties of action spontaneously represented when mentally simulating moving one's hand. The kinematic configuration of the body represented and transformed in mental simulations was not fixed or canonical but corresponded to one's current configuration. Mental simulation time mimicked movement time for natural efficient movement from a posture midway between each of the hand's joint limits into many other postures. Equal time was required for simulated and real movements into more common, comfortable postures; shorter but proportional time was required for simulated movement than real movement into less common postures that involved longer trajectories, coordinated activity at more joints, motion near extremes of joint limits, and uncomfortable kinesthetic sensations. The findings suggest that sensorimotor structures support mental simulations of actions.},
author = {Parsons, Lawrence M},
doi = {10.1037/0096-1523.20.4.709},
file = {:Users/jhamrick/Dropbox/Papers/1994/Parsons - Temporal and kinematic properties of motor behavior reflected in mentally simulated action.pdf:pdf},
isbn = {0096-1523 (Print)\n0096-1523 (Linking)},
issn = {0096-1523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
month = {aug},
number = {4},
pages = {709--730},
pmid = {8083630},
title = {Temporal and kinematic properties of motor behavior reflected in mentally simulated action},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8083630},
volume = {20},
year = {1994}
}
@article{Sanborn2010,
author = {Sanborn, Adam N. and Griffiths, Thomas L and Shiffrin, Richard M.},
doi = {10.1016/j.cogpsych.2009.07.001},
file = {:Users/jhamrick/Dropbox/Papers/2010/Sanborn, Griffiths, Shiffrin - Uncovering mental representations with Markov chain Monte Carlo.pdf:pdf},
issn = {00100285},
journal = {Cognitive Psychology},
number = {2},
pages = {63--106},
title = {Uncovering mental representations with {Markov} chain {Monte Carlo}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010028509000449},
volume = {60},
year = {2010}
}
@article{Saxe2005,
author = {Saxe, Rebecca},
doi = {10.1016/j.tics.2005.01.012},
file = {:Users/jhamrick/Dropbox/Papers/2005/Saxe - Against simulation the argument from error.pdf:pdf},
journal = {Trends in Cognitive Sciences},
number = {4},
pages = {174--179},
title = {Against simulation: the argument from error},
volume = {9},
year = {2005}
}
@article{Schulman2013,
abstract = {We introduce an algorithm for tracking de- formable objects from a sequence of point clouds. The proposed tracking algorithm is based on a probabilistic generative model that incorporates observations of the point cloud and the physical properties of the tracked object and its environment. We propose a modified expectation maximization algorithm to perform maximum a posteriori estimation to update the state estimate at each time step. Our modification makes it practical to perform the inference through calls to a physics simulation engine. This is significant because (i) it allows for the use of highly optimized physics simulation engines for the core computations of our tracking algorithm, and (ii) it makes it possible to naturally, and efficiently, account for physical constraints imposed by collisions, grasping actions, and material properties in the observation updates. Even in the presence of the relatively large occlusions that occur during manipulation tasks, our algorithm is able to robustly track a variety of types of deformable objects, including ones that are one-dimensional, such as ropes; two- dimensional, such as cloth; and three-dimensional, such as sponges. Our implementation can track these objects in real time.},
author = {Schulman, John and Lee, Alex X and Ho, Jonathan and Abbeel, Pieter},
doi = {10.1109/ICRA.2013.6630714},
file = {:Users/jhamrick/Dropbox/Papers/2013/Schulman et al. - Tracking deformable objects with point clouds.pdf:pdf},
isbn = {9781467356411},
issn = {10504729},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
title = {Tracking deformable objects with point clouds},
year = {2013}
}
@article{Schwartz1999a,
abstract = {Physical imagery occurs when people imagine one object causing a change to a second object. To make inferences through physical imagery, people must represent information that coordinates the interactions among the imagined objects. The current research contrasts two proposals for how this coordinating information is realized in physical imagery. In the traditional kinematic formulation, imagery transformations are coordinated by geometric information in analog spatial representations. In the dynamic formulation, transformations may also be regulated by analog representations of force and resistance. Four experiments support the dynamic formulation. They show, for example, that without making changes to the spatial properties of a problem, dynamic perceptual information (e.g., torque) and beliefs about physical properties (e. g., viscosity) affect the inferences that people draw through imagery. The studies suggest that physical imagery is not so much an analog of visual perception as it is an analog of physical action. A simple model that represents force as a rate helps explain why inferences can emerge through imagined actions even though people may not know the answer explicitly. It also explains how and when perception, beliefs, and learning can influence physical imagery.},
author = {Schwartz, Daniel L},
doi = {10.1006/cogp.1998.0702},
file = {:Users/jhamrick/Dropbox/Papers/1999/Schwartz - Physical imagery kinematic versus dynamic models.pdf:pdf},
issn = {0010-0285},
journal = {Cognitive Psychology},
month = {may},
number = {3},
pages = {433--464},
pmid = {10328859},
title = {Physical imagery: kinematic versus dynamic models},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10328859},
volume = {38},
year = {1999}
}
@article{Shepard1971,
author = {Shepard, Roger N and Metzler, Jacqueline},
doi = {10.1126/science.171.3972.701},
file = {:Users/jhamrick/Dropbox/Papers/1971/Shepard, Metzler - Mental Rotation of Three-Dimensional Objects.pdf:pdf},
journal = {Science},
number = {3972},
pages = {701--703},
title = {Mental Rotation of Three-Dimensional Objects},
volume = {171},
year = {1971}
}
@article{Stam1999,
author = {Stam, Jos},
doi = {10.1145/311535.311548},
file = {:Users/jhamrick/Dropbox/Papers/1999/Stam - Stable Fluids.pdf:pdf},
journal = {Proceedings of the 26th Annual Conference on Computer Graphics and Interactive Techniques},
keywords = {advected textures,animation of fluids,ena,gaseous phenom-,im-,interactive modeling,navier-stokes,plicit elliptic pde solvers,stable solvers},
title = {Stable Fluids},
year = {1999}
}
@article{Stich1992,
author = {Stich, Stephen P and Nichols, Shaun},
doi = {10.1111/j.1468-0017.1992.tb00196.x},
file = {:Users/jhamrick/Dropbox/Papers/1992/Stich, Nichols - Folk Psychology Simulation or Tacit Theory.pdf:pdf},
journal = {Mind \& Language},
number = {1-2},
pages = {35--71},
title = {Folk Psychology: Simulation or Tacit Theory?},
volume = {7},
year = {1992}
}
@article{Teglas2011,
abstract = {Many organisms can predict future events from the statistics of past experience, but humans also excel at making predictions by pure reasoning: integrating multiple sources of information, guided by abstract knowledge, to form rational expectations about novel situations, never directly experienced. Here, we show that this reasoning is surprisingly rich, powerful, and coherent even in preverbal infants. When 12-month-old infants view complex displays of multiple moving objects, they form time-varying expectations about future events that are a systematic and rational function of several stimulus variables. Infants' looking times are consistent with a Bayesian ideal observer embodying abstract principles of object motion. The model explains infants' statistical expectations and classic qualitative findings about object cognition in younger babies, not originally viewed as probabilistic inferences.},
author = {Teglas, Erno and Vul, Edward and Girotto, Vittorio and Gonzalez, Michel and Tenenbaum, Joshua B and Bonatti, Luca L},
doi = {10.1126/science.1196404},
file = {:Users/jhamrick/Dropbox/Papers/2011/Teglas et al. - Pure reasoning in 12-month-old infants as probabilistic inference.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Bayes Theorem,Child Development,Cognition,Female,Humans,Infant,Male,Models,Monte Carlo Method,Probability,Statistical,Visual Perception},
month = {may},
number = {6033},
pages = {1054--9},
pmid = {21617069},
title = {Pure reasoning in 12-month-old infants as probabilistic inference},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21617069},
volume = {332},
year = {2011}
}
@article{Tenenbaum2001,
abstract = {Shepard has argued that a universal law should govern generalization across different domains of perception and cognition, as well as across organisms from different species or even different planets. Starting with some basic assumptions about natural kinds, he derived an exponential decay function as the form of the universal generalization gradient, which accords strikingly well with a wide range of empirical data. However, his original formulation applied only to the ideal case of generalization from a single encountered stimulus to a single novel stimulus, and for stimuli that can be represented as points in a continuous metric psychological space. Here we recast Shepard's theory in a more general Bayesian framework and show how this naturally extends his approach to the more realistic situation of generalizing from multiple consequential stimuli with arbitrary representational structure. Our framework also subsumes a version of Tversky's set-theoretic model of similarity, which is conventionally thought of as the primary alternative to Shepard's continuous metric space model of similarity and generalization. This unification allows us not only to draw deep parallels between the set-theoretic and spatial approaches, but also to significantly advance the explanatory power of set-theoretic models.},
author = {Tenenbaum, Joshua B and Griffiths, Thomas L},
doi = {10.1017/S0140525X01000061},
file = {:Users/jhamrick/Dropbox/Papers/2001/Tenenbaum, Griffiths - Generalization, similarity, and Bayesian inference.pdf:pdf},
issn = {0140-525X},
journal = {The Behavioral and Brain Sciences},
keywords = {additive clustering,bayesian inference,categorization,concept learning,contrast model,features,generalization,logical space,psycho-,similarity},
pages = {629--640; discussion 652--791},
pmid = {12048947},
title = {Generalization, similarity, and {Bayesian} inference},
volume = {24},
year = {2001}
}
@article{Tenenbaum2011,
abstract = {In coming to understand the world-in learning concepts, acquiring language, and grasping causal relations-our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
author = {Tenenbaum, Joshua B and Kemp, Charles and Griffiths, Thomas L and Goodman, Noah D},
doi = {10.1126/science.1192788},
file = {:Users/jhamrick/Dropbox/Papers/2011/Tenenbaum et al. - How to grow a mind statistics, structure, and abstraction.pdf:pdf},
issn = {1095-9203},
journal = {Science},
month = {mar},
number = {6022},
pages = {1279--85},
pmid = {21393536},
title = {How to grow a mind: statistics, structure, and abstraction.},
volume = {331},
year = {2011}
}
@article{Trickett2007,
abstract = {The term conceptual simulation refers to a type of everyday reasoning strategy commonly called "what if" reasoning. It has been suggested in a number of contexts that this type of reasoning plays an important role in scientific discovery; however, little direct evidence exists to support this claim. This article proposes that conceptual simulation is likely to be used in situations of informational uncertainty, and may be used to help scientists resolve that uncertainty. We conducted two studies to investigate the relationship between conceptual simulation and informational uncertainty. Study 1 was an in vivo study of expert scientists; the results suggest that scientists do use conceptual simulation in situations of informational uncertainty, and that they use conceptual simulation to make inferences from their data using the analogical reasoning process of alignment by similarity detection. Study 2 experimentally manipulated experts' level of uncertainty and provides further support for the hypothesis that conceptual simulation is more likely to be used in situations of informational uncertainty. Finally, we discuss the relationship between conceptual simulation and other types of reasoning using qualitative mental models.},
author = {Trickett, Susan Bell and Trafton, J. Gregory},
doi = {10.1080/03640210701530771},
file = {:Users/jhamrick/Dropbox/Papers/2007/Trickett, Trafton - What if{\ldots} The Use of Conceptual Simulations in Scientific Reasoning.pdf:pdf},
isbn = {0364021070153},
issn = {0364-0213},
journal = {Cognitive Science},
keywords = {analogy,in vivo observation,model-based reasoning,problem solving,scientific discovery,scientific reasoning,visualization},
month = {sep},
number = {5},
pages = {843--875},
pmid = {21635319},
title = {{``What if{\ldots}''}: The Use of Conceptual Simulations in Scientific Reasoning},
volume = {31},
year = {2007}
}
@article{Tversky1974,
abstract = {This article described three heuristics that are employed in making judgements under uncertainty: (i) representativeness, which is usually employed when people are asked to judge the probability that an object or event A belongs to class or process B; (ii) availability of instances or scenarios, which is often employed when people are asked to assess the frequency of a class or the plausibility of a particular development; and (iii) adjustment from an anchor, which is usually employed in numerical prediction when a relevant value is available. These heuristics are highly economical and usually effective, but they lead to systematic and predictable errors. A better understanding of these heuristics and of the biases to which they lead could improve judgements and decisions in situations of uncertainty.},
author = {Tversky, Amos and Kahneman, Daniel},
doi = {10.1126/science.185.4157.1124},
file = {:Users/jhamrick/Dropbox/Papers/1974/Tversky, Kahneman - Judgment under Uncertainty Heuristics and Biases.pdf:pdf},
isbn = {0036-8075 (Print)\r0036-8075 (Linking)},
issn = {0036-8075},
journal = {Science},
month = {sep},
number = {4157},
pages = {1124--1131},
pmid = {17835457},
title = {Judgment under Uncertainty: Heuristics and Biases},
volume = {185},
year = {1974}
}
@article{Ullman2012,
abstract = {We present an algorithmic model for the development of children's intuitive theories within a hierarchical Bayesian framework, where theories are described as sets of logical laws generated by a probabilistic context-free grammar. We contrast our approach with connectionist and other emergentist approaches to modeling cognitive development. While their subsymbolic representations provide a smooth error surface that supports efficient gradient-based learning, our symbolic representations are better suited to capturing children's intuitive theories but give rise to a harder learning problem, which can only be solved by exploratory search. Our algorithm attempts to discover the theory that best explains a set of observed data by performing stochastic search at two levels of abstraction: an outer loop in the space of theories and an inner loop in the space of explanations or models generated by each theory given a particular dataset. We show that this stochastic search is capable of learning appropriate theories in several everyday domains and discuss its dynamics in the context of empirical studies of children's learning. {\^{a}}º We give an algorithmic level account of Hierarchical Bayesian learning. {\^{a}}º We contrast this approach with connectionism and emergentism. {\^{a}}º A Markov Chain Monte Carlo explores theories constructed by horn clause logic. {\^{a}}º The algorithm constructs theories of 2 domains, taxonomy and simplified magnetism. {\^{a}}º Predictions resulting from the learning dynamics are considered.},
author = {Ullman, Tomer D and Goodman, Noah D and Tenenbaum, Joshua B},
doi = {10.1016/j.cogdev.2012.07.005},
file = {:Users/jhamrick/Dropbox/Papers/2012/Ullman, Goodman, Tenenbaum - Theory learning as stochastic search in the language of thought.pdf:pdf},
issn = {08852014},
journal = {Cognitive Development},
keywords = {algorithms,bayesian,bayesian models,cognition,cognitive_development,computational_cognitive_science,hierarchical_bayesian_models,induction,inductive_learning,language of thought,mcmc,sampling,search},
month = {aug},
number = {4},
title = {Theory learning as stochastic search in the language of thought},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0885201412000445 citeulike-article-id:11044312\nhttp://dx.doi.org/10.1016/j.cogdev.2012.07.005},
volume = {27},
year = {2012}
}
@article{VanDerMerwe2000,
author = {{Van Der Merwe}, Rudolph and Doucet, Arnaud and {De Freitas}, Nando and Wan, Eric},
file = {:Users/jhamrick/Dropbox/Papers/2000/Van Der Merwe et al. - The Unscented Particle Filter.pdf:pdf},
journal = {Advances in Neural Information Processing Systems},
title = {The Unscented Particle Filter},
url = {http://papers.nips.cc/paper/1818-the-unscented-particle-filter.pdf},
volume = {13},
year = {2000}
}
@article{Veiga2015,
author = {Veiga, Filipe and van Hoof, Herke and Peters, Jan and Hermans, Tucker},
file = {:Users/jhamrick/Dropbox/Papers/2015/Veiga et al. - Stabilizing Novel Objects by Learning to Predict Tactile Slip.pdf:pdf},
journal = {Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems},
title = {Stabilizing Novel Objects by Learning to Predict Tactile Slip},
url = {http://www.ausy.tu-darmstadt.de/uploads/Site/EditPublication/IROS2015veiga.pdf},
year = {2015}
}
@article{Vul2014,
abstract = {In many learning or inference tasks human behavior approximates that of a Bayesian ideal observer, suggesting that, at some level, cognition can be described as Bayesian inference. However, a number of findings have highlighted an intriguing mismatch between human behavior and standard assumptions about optimality: People often appear to make decisions based on just one or a few samples from the appropriate posterior probability distribution, rather than using the full distribution. Although sampling-based approximations are a common way to implement Bayesian inference, the very limited numbers of samples often used by humans seem insufficient to approximate the required probability distributions very accurately. Here, we consider this discrepancy in the broader framework of statistical decision theory, and ask: If people are making decisions based on samples—but as samples are costly—how many samples should people use to optimize their total expected or worst-case reward over a large number of decisions? We find that under reasonable assumptions about the time costs of sampling, making many quick but locally suboptimal decisions based on very few samples may be the globally optimal strategy over long periods. These results help to reconcile a large body of work showing sampling-based or probability matching behavior with the hypothesis that human cognition can be understood in Bayesian terms, and they suggest promising future directions for studies of resource-constrained cognition.},
author = {Vul, Edward and Goodman, Noah D and Griffiths, Thomas L and Tenenbaum, Joshua B},
doi = {10.1111/cogs.12101},
file = {:Users/jhamrick/Dropbox/Papers/2014/Vul et al. - One and Done Optimal Decisions From Very Few Samples.pdf:pdf},
isbn = {1551-6709},
issn = {03640213},
journal = {Cognitive Science},
keywords = {43 vassar st,bayesian,bayesian models,bounded rationality,brain and cognitive science,cess models,computational,computational modeling,edu,inference,jbt,joshua b,mit,pro-,sampling,tenenbaum},
number = {4},
pages = {599--637},
pmid = {24467492},
title = {One and Done? {Optimal} Decisions From Very Few Samples},
volume = {38},
year = {2014}
}
@article{Weiss2002,
author = {Weiss, Yair and Simoncelli, Eero P. and Adelson, Edward H},
doi = {10.1038/nn858},
file = {:Users/jhamrick/Dropbox/Papers/2002/Weiss, Simoncelli, Adelson - Motion illusions as optimal percepts.pdf:pdf},
issn = {10976256},
journal = {Nature Neuroscience},
number = {6},
pages = {598--604},
title = {Motion illusions as optimal percepts},
url = {http://www.nature.com/doifinder/10.1038/nn858},
volume = {5},
year = {2002}
}
@article{White2012a,
author = {White, Peter A.},
doi = {10.1037/a0025587},
file = {:Users/jhamrick/Dropbox/Papers/2012/White - The experience of force The role of haptic experience of forces in visual perception of object motion and interactions, mental s.pdf:pdf},
issn = {1939-1455},
journal = {Psychological Bulletin},
keywords = {force perception,haptics,mental simulation,perceived object motion,representational},
number = {4},
pages = {589--615},
title = {The experience of force: The role of haptic experience of forces in visual perception of object motion and interactions, mental simulation, and motion-related judgments.},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0025587},
volume = {138},
year = {2012}
}
@article{White2012,
author = {White, Peter A.},
doi = {10.3758/s13423-012-0302-2},
file = {:Users/jhamrick/Dropbox/Papers/2012/White - The impetus theory in judgments about object motion A new perspective.pdf:pdf},
journal = {Psychonomic Bulletin \& Review},
keywords = {high-order cognition,impetus theory,representational momentum},
title = {The impetus theory in judgments about object motion: A new perspective},
url = {http://www.springerlink.com/index/H6U7446X64120X16.pdf},
year = {2012}
}
@article{Xie2015,
abstract = {In this paper, we present a robotic model-based reinforcement learning method that combines ideas from model identification and model predictive control. We use a feature-based representation of the dynamics that allows the dynamics model to be fitted with a simple least squares procedure, and the features are identified from a high-level specification of the robot's morphology, consisting of the number and connectivity structure of its links. Model predictive control is then used to choose the actions under an optimistic model of the dynamics, which produces an efficient and goal-directed exploration strategy. We present real time experimental results on standard benchmark problems involving the pendulum, cartpole, and double pendulum systems. Experiments indicate that our method is able to learn a range of benchmark tasks substantially faster than the previous best methods. To evaluate our approach on a realistic robotic control task, we also demonstrate real time control of a simulated 7 degree of freedom arm.},
archivePrefix = {arXiv},
arxivId = {1509.06824},
author = {Xie, Christopher and Patil, Sachin and Moldovan, Teodor and Levine, Sergey and Abbeel, Pieter},
eprint = {1509.06824},
file = {:Users/jhamrick/Dropbox/Papers/2015/Xie et al. - Model-based Reinforcement Learning with Parametrized Physical Models and Optimism-Driven Exploration.pdf:pdf},
journal = {arXiv preprint arXiv:1509.06824v1 [cs.LG]},
title = {Model-based Reinforcement Learning with Parametrized Physical Models and Optimism-Driven Exploration},
url = {http://arxiv.org/abs/1509.06824},
year = {2015}
}
@article{Yuille2006,
abstract = {We argue that the study of human vision should be aimed at determining how humans perform natural tasks with natural images. Attempts to understand the phenomenology of vision from artificial stimuli, although worthwhile as a starting point, can lead to faulty generalizations about visual systems, because of the enormous complexity of natural images. Dealing with this complexity is daunting, but Bayesian inference on structured probability distributions offers the ability to design theories of vision that can deal with the complexity of natural images, and that use 'analysis by synthesis' strategies with intriguing similarities to the brain. We examine these strategies using recent examples from computer vision, and outline some important imlications for cognitive science. ?? 2006 Elsevier Ltd. All rights reserved.},
author = {Yuille, Alan L and Kersten, Daniel},
doi = {10.1016/j.tics.2006.05.002},
file = {:Users/jhamrick/Dropbox/Papers/2006/Yuille, Kersten - Vision as Bayesian inference analysis by synthesis.pdf:pdf},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {7},
pages = {301--308},
pmid = {16784882},
title = {Vision as {Bayesian} inference: analysis by synthesis?},
volume = {10},
year = {2006}
}
@article{Zago2005,
abstract = {Prevailing views on how we time the interception of a moving object assume that the visual inputs are informationally sufficient to estimate the time-to-contact from the object's kinematics. However, there are limitations in the visual system that raise questions about the general validity of these theories. Most notably, vision is poorly sensitive to arbitrary accelerations. How then does the brain deal with the motion of objects accelerated by Earth's gravity? Here we review evidence in favor of the view that the brain makes the best estimate about target motion based on visually measured kinematics and an a priori guess about the causes of motion. According to this theory, a predictive model is used to extrapolate time-to-contact from the expected kinetics in the Earth's gravitational field.},
author = {Zago, Myrka and Lacquaniti, Francesco},
doi = {10.1088/1741-2560/2/3/S04},
file = {:Users/jhamrick/Dropbox/Papers/2005/Zago, Lacquaniti - Visual perception and interception of falling objects a review of evidence for an internal model of gravity.pdf:pdf},
issn = {1741-2560},
journal = {Journal of Neural Engineering},
month = {sep},
number = {3},
pages = {S198--208},
pmid = {16135884},
title = {Visual perception and interception of falling objects: a review of evidence for an internal model of gravity.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16135884},
volume = {2},
year = {2005}
}
@article{Zheng2014,
abstract = {Detecting potential dangers in the environment is a fundamental ability of living beings. In order to endure such ability to a robot, this paper presents an algorithm for detecting potential falling objects, i.e. physically unsafe objects, given an input of 3D point clouds captured by the range sensors. We formulate the falling risk as a probability or a potential that an object may fall given human action or certain natural disturbances, such as earthquake and wind. Our approach differs from traditional object detection paradigm, it first infers hidden and situated “causes (disturbance) of the scene, and then introduces intuitive physical mechanics to predict possible “effects (falls) as consequences of the causes. In particular, we infer a disturbance field by making use of motion capture data as a rich source of common human pose movement. We show that, by applying various disturbance fields, our model achieves a human level recognition rate of potential falling objects on a dataset of challenging and realistic indoor scenes.},
author = {Zheng, Bo and Zhao, Yibiao and Yu, Joey C. and Ikeuchi, Katsushi and Zhu, Song-Chun},
doi = {10.1109/ICRA.2014.6907351},
file = {:Users/jhamrick/Dropbox/Papers/2014/Zheng et al. - Detecting Potential Falling Objects by Inferring Human Action and Natural Disturbance.pdf:pdf},
isbn = {9781479936847},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
title = {Detecting Potential Falling Objects by Inferring Human Action and Natural Disturbance},
year = {2014}
}
@article{Schulman2013,
abstract = {We consider the problem of teaching robots by demonstration how to perform manipulation tasks, in which the geometry (including size, shape, and pose) of the relevant objects varies from trial to trial. We present a method, which we call trajectory transfer, for adapting a demonstrated trajectory from the geometry at training time to the geometry at test time. Trajectory transfer is based on nonrigid registration, which computes a smooth transformation from the training scene onto the testing scene. We then show how to perform a multi-step task by repeatedly looking up the nearest demonstration and then applying trajectory transfer. As our main experimental validation, we enable a PR2 robot to autonomously tie five different types of knots in rope},
author = {Schulman, John and Ho, Jonathan and Lee, Cameron and Abbeel, Pieter},
file = {:Users/jhamrick/Dropbox/Papers/2013/Schulman et al. - Learning from Demonstrations Through the Use of Non-Rigid Registration.pdf:pdf},
journal = {Proceedings of the 16th International Symposium on Robotics Research},
mendeley-groups = {Quals/Simulation and physical reasoning in computer science and robotics/Physical reasoning without dynamics models},
title = {Learning from Demonstrations Through the Use of Non-Rigid Registration},
url = {http://www.cs.berkeley.edu/~pabbeel/papers/SchulmanHoLeeAbbeel_ISRR2013.pdf},
year = {2013}
}
@article{Levine2015,
archivePrefix = {arXiv},
arxivId = {1501.05611v1},
author = {Levine, Sergey and Wagener, Nolan and Abbeel, Pieter},
eprint = {1501.05611v1},
file = {:Users/jhamrick/Dropbox/Papers/2015/Levine, Wagener, Abbeel - Learning Contact-Rich Manipulation Skills with Guided Policy Search.pdf:pdf},
isbn = {9781479969227},
journal = {Proceedings of the IEEE International Conference on Robotics and Automation},
mendeley-groups = {Quals/Simulation and physical reasoning in computer science and robotics/Physical reasoning without dynamics models},
title = {Learning Contact-Rich Manipulation Skills with Guided Policy Search},
url = {http://arxiv.org/abs/1501.05611v1},
year = {2015}
}

